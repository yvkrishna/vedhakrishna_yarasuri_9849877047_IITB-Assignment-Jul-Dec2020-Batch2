## Report for the OCR application on Forms ( Assignment for IITB Internship )

## Table of Contents
- [Myself In Brief](#myselfInBrief)
- [Analysis](#analysis)
- [Problems Faced](#problems-faced)

## Myself In Brief
<!-- Before Going into detailed report, I would like to give a brief insights about me in this domain.<br>
I have -->

## Analysis
I am new to deep learning to text related applications, but I have looked for detailed information regarding OCR systems and I have tried my level best in reaching upto a good level.

<h4>Data Augumentation and Image Pre-Processing</h4><br>

<p>The dataset which I have obtained contains upto 2000 images and their corresponding ground truths[]. Since the dataset is very small, various data agumentation techniques such as Image rotation has been implemented.Especially for this problem statement, image blurring has been implemented which can serve as better data agumentation technique. To decrease the computation of the deep learning model, pre-processing techiniques such as resizing, normalization have been used.</p>
---
<h4>Pre-Trained Inception-Resnet-V3 and feature Extraction</h4><br>

<p>From[], Inception model achieved higher accuracies than other pre-trained models. Features are taken out from layers and then applied attention mask and are fed to lstm to give the text within the image.</p>

<p>the authors of [] have worked in ocr detection systems using FSNS dataset. They have taken features from inception-v2, inception-v3 and inception-resnet-v2. These models achieved state-of-the-art performance on the Imagenet classification challenge. They extracted various features from various layers and found not much changes for the deeper layers. Referring this, I have implemented inception-resnet-v2 as it gave 84.2% accuracy outperforming all other models. Mixed 7a, block8_1_conv has been choosen as feature extraction layers as the output tensor shape is lesser and still get a higher accuracies. Using mixed_7a,block8_1_conv  the output feature size is 8, 8, 2080. The output feature is then unrolled to a shape of 64,2080 . The resulting features are then plotted and cached for training the later model.</p>
---

<h4>Attention Based Encoder-Decoder</h4><br>

<p>The features from the feature extraction model are then used to train the attention based model. From the sequence models from deeplearning specialization. I have learnt the attention models concept and tried to replicate the attention model, but then I could not able to make a great leap. Later using the examples from the 
tensorflow's Image captioning, I have implemented object oriented models such as CNN Encoder, Bahdanau-Attention, GRU_Encoder.[] computed the attention masks using rnn and feature masks. Using the product of attention masks and features they computed the weights and finally output the result.</p>

---
## Problems Faced

<h3>List of problems faced</h3>

- [Dataset](#dataset)
- [Designing Sequence Models](#designing-sequence-models)
- [Computing Time](#computing-time)

<h4>Dataset</h4>
<p>Understanding dataset generator repositories are even mode difficult than getting the proper dataset. As per the guidelines given in the document, I have gone through many repositories and finally found the model which generates the synthetic data. I tried to understand Text_Renderer and Text_Recognition_Data_Generator, But there I could find only 50 images. . They have given few examples on generation of the data but due to the heavy file and low internet connectivity in my place at that time, I could not able to download the big dataset. Later, after looking at several repositories and online tools, I found a dataset generated by IIIT Hyderabad which contains croped images of street signs and images of various business flexes on the road. This is comparabally small dataset but easier to start with.</p>


<h3>Designing Sequence Models</h4>

<p>I have a good experience in working with conv networks and pretrained models, but not much on text based applicaitons. So initially I could not understand the suggested paper properly. Later after spending 3 days in rnn's and lstm's and mainly attention models from sequence models in coursera. From the knowledge I gained from the course, I have tried to implement attention based encoder-decoder but I could not able to complete it. Later I have seen examples from tensorflow's documentation on language translation and image captioning and tried to replicate encoder, decoder, bahdanau attention classes.</p>

<h3>Computing Time</h4>

<p>I have a laptop with i5 CPU @ 1.60GHz processor speed. Due to the the complex image feature extraction on the dataset, it gets slow down and for this reason, I have started coding in colab. But due to network issues, I have to spend a lot of time in uploading the corresponding files to colab. Due to these conditions, I found difficulty in completing my daily targets.</p>

