{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_file_OCR.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8m8WOPTwpy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply, RepeatVector, Dense, Activation, Lambda\n",
        "from keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR97shHlw5-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "import os\n",
        "from PIL import Image, ImageFilter\n",
        "import h5py\n",
        "import tarfile\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import cv2\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import csv  \n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE-gQZJ8TXEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflowjs\n",
        "import tensorflowjs as tfjs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqsHj1rkQJgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pytest for testing the functions\n",
        "!pip install pytest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHk4axl8W6D1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "   Dataset is obtained from file 'IIIT5K-Word_V3.0.tar.gz'.\n",
        "   The Dataset contains several files and 2 folders train and test.\n",
        "   Files named traindata.m and testdata.m contains all the information related\n",
        "       to the train and test images and their annotations respectively.\n",
        "'''\n",
        "os.chdir('/content')\n",
        "tar = tarfile.open('IIIT5K-Word_V3.0.tar.gz')\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pujVgS_zW9uB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('IIIT5K')\n",
        "base_dir = os.getcwd()\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir,'test')\n",
        "print(train_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih308zqJW9w_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_imgs_train = len(os.listdir(train_dir))\n",
        "num_imgs_test = len(os.listdir(test_dir))\n",
        "print('''\n",
        "  Dataset Before Pre-processing\n",
        "''')\n",
        "print(\"number of images in training dataset is {}\".format(num_imgs_train))\n",
        "print(\"number of images in testing dataset is {}\".format(num_imgs_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ijxbzs_3Dx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/IIIT5K')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8wg_gtuXHZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_generation(filename):\n",
        "\n",
        "  os.chdir('/content/IIIT5K')\n",
        "  text_file = open(filename, \"r\")\n",
        "  text = text_file.readlines()\n",
        "  text_list = [ word[0:len(word)-1] for word in text]\n",
        "\n",
        "  #Y = np.array([string_to_int(word,T_Y,vocab) for word in text_list])\n",
        "\n",
        "  return text_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQOUgbMe3BkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = label_generation(\"Train_labels.txt\")\n",
        "print(f\"few of the dataset labels are {train_labels[0:3]}\")\n",
        "train_label_img_locations = label_generation(\"Train_labels_img_loc.txt\")\n",
        "print(f\"few of the image locations are{train_label_img_locations[0:3]}\")\n",
        "dataset = []\n",
        "\n",
        "i=0\n",
        "for image in train_label_img_locations:\n",
        "  dataset.append((image,train_labels[i]))\n",
        "  i+=1\n",
        "print(f\"few of the image to image-locations are {dataset[0:3]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmxK6dtmXHiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rotateImages(rotationAmt):\n",
        "  '''\n",
        "    rotateImages is used as one of the image augumentation techniques to \n",
        "    increase the dataset thereby increasing the accuracy.\n",
        "\n",
        "    rotateImages function rotates images in the current directory.\n",
        "\n",
        "   Args:\n",
        "   rotationAmt : int. The value of rotation in the image.\n",
        "   \n",
        "  '''\n",
        "  # for each image in the current directory\n",
        "  i = 0\n",
        "  for image in train_label_img_locations:\n",
        "    # check if the image is already rotated. \n",
        "    if (image.find(\"rot\") == -1): \n",
        "      img = Image.open(image)\n",
        "      # get the image name\n",
        "      img_name = list(image.split(\".\"))[0]\n",
        "      rotimg = img.rotate(rotationAmt)\n",
        "      # saving the image with its rotation information as well.\n",
        "      rotimg.save(img_name+\"rot\"+str(rotationAmt)+\".jpg\")\n",
        "      img.close()  \n",
        "      train_labels.append(train_labels[i])\n",
        "      dataset.append((img_name+\"rot\"+str(rotationAmt)+\".jpg\",train_labels[i]))\n",
        "      i+=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2siniHn1WYq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' Unit tests for testing rotateImages '''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hSGspcwXdFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def addBlur():\n",
        "  '''\n",
        "    Adds Blur to the images.\n",
        "    This function will list out all the images in the current directory and \n",
        "    applies blur to the image and saves it in the same folder.\n",
        "  '''\n",
        "  # for each image in the current directory\n",
        "  i = 0\n",
        "  # for each image in the current directory\n",
        "  for image in train_label_img_locations:\n",
        "    img = Image.open(image)\n",
        "    # adds blur to the image using ImageFilter.Blur\n",
        "    blured_image = img.filter(ImageFilter.BLUR)\n",
        "    # get the image name\n",
        "    img_name = list(image.split(\".\"))[0]\n",
        "    # saving the image by adding the blur feature.\n",
        "    blured_image.save(img_name+\"blur.jpg\")\n",
        "    train_labels.append(train_labels[i])\n",
        "    dataset.append((img_name+\"blur.jpg\",train_labels[i]))\n",
        "    i+=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZfdEoLsMCNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing():\n",
        "  '''\n",
        "  preprocessing techniques such as image rotation and image blur are applied to \n",
        "  the images in the current directory.\n",
        "  '''\n",
        "  # Rotating images with an angle of 15 deg.\n",
        "  rotateImages(15)\n",
        "  # Rotating images with an angle of -15 deg.\n",
        "  rotateImages(-15)\n",
        "  # Blur images in the current Directory\n",
        "  addBlur()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_HktKP1Mxy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('train')\n",
        "# Preprocessing the images located in the train directory \n",
        "preprocessing()\n",
        "os.chdir('/content/IIIT5K')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ4bjjpnt4RM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"few of the dataset labels are {train_labels[2000:2003]}\")\n",
        "print(f\"few of the image to image-locations are {dataset[2000:2003]}\")\n",
        "print(('1009_2'+'blur.jpg', 'YOU') in dataset)\n",
        "print(('1009_2'+'rot15.jpg', 'YOU') in dataset)\n",
        "print(('1009_2'+'rot-15.jpg', 'YOU') in dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIo7-3eOr8LW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_imgs_train = len(os.listdir(train_dir))\n",
        "num_imgs_test = len(os.listdir(test_dir))\n",
        "print('''\n",
        "  Dataset After Pre-processing\n",
        "''')\n",
        "print(\"number of images in training dataset is {}\".format(num_imgs_train))\n",
        "print(\"number of images in testing dataset is {}\".format(num_imgs_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqgoNNXevUlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHO6mcPMJQrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "  loading inception_resnet_v2 trained on imagenet dataset as per https://arxiv.org/pdf/1704.03549.pdf\n",
        "  inception_resnet_v2 model is used as a feature extractor. \n",
        "  Later the features obtained are then passed to sequence to sequence model ( attention model ).\n",
        "'''\n",
        "pre_trained_model = tf.keras.applications.InceptionResNetV2(include_top=True, weights='imagenet', pooling=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYVdO01LJQwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# freezing the weights of the model and removing the last layer\n",
        "pre_trained_model.trainable = False\n",
        "pre_trained_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50huDsy5Xlwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_and_process_img(image_path):\n",
        "  '''\n",
        "    Loads image in the Argument and and converts to size=(229,229,3) and\n",
        "    returns numpy.ndarray used for getting features from the pre_trained_model.\n",
        "\n",
        "    Args : \n",
        "    image_path : str. location path of the image\n",
        "\n",
        "    Return : \n",
        "    img : numpy.ndarray . pre-processed image for passing into pre_trained_model\n",
        "  '''\n",
        "\n",
        "  # Load image with resizing it to a size of (229,229,3) \n",
        "  img = image.load_img(image_path, target_size=(299,299, 3))\n",
        "  img = image.img_to_array(img)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "  return img, image_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MegNRauZQi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Getting important layers for feature extraction from pre_trained_model.\n",
        "# The layers are selected by referring to https://arxiv.org/pdf/1704.03549.pdf\n",
        "imp_layers = ['mixed_7a','block8_1_conv']\n",
        "\n",
        "# Taking out features from layer 'mixed_7a'\n",
        "# with reference to the paper in https://arxiv.org/pdf/1704.03549.pdf\n",
        "# an accuracy of 0.819 is achieved with the layer 'mixed_7a'\n",
        "\n",
        "layer_name = 'block8_1_conv'\n",
        "\n",
        "# Taking output from 'mixed_7a'\n",
        "layer_output = pre_trained_model.get_layer(layer_name).output\n",
        "\n",
        "# Generating a substance model from the pre_trained_model.\n",
        "# model with input layer of pre_trained_model and output layer of 'mixed_7a'\n",
        "feature_extraction_model = tf.keras.Model(inputs=pre_trained_model.input, outputs=layer_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NISdGsAtRcF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "export_path_keras = \"./feature_extraction_model.h5\"\n",
        "print(export_path_keras)\n",
        "\n",
        "feature_extraction_model.save(export_path_keras)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuRPJXMaSQ7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "export_path = \"./feature_extraction_model\"\n",
        "print(export_path)\n",
        "\n",
        "tf.saved_model.save(feature_extraction_model,export_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MioJQcSTFy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r mode.zip {export_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSLVLMQqTOpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('./mode.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoRfRSPzULBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1C0H0w2Tftu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tensorflowjs_converter --input_format=keras ./feature_extraction_model/feature_extraction_model.h5 ./web_feature_extractor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGNFpQibVHj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r js_model.zip web_feature_extractor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mreYsObdU1l8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('js_model.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9FssgqrXt8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#os.chdir('train')\n",
        "\n",
        "# Loading and processing a image '1009_2.png'\n",
        "input_data = load_and_process_img('1009_2.png')\n",
        "\n",
        "# getting features from the feature_extraction_model\n",
        "result = feature_extraction_model.predict(input_data)\n",
        "\n",
        "print(list(result.shape))\n",
        "(m,n_H,n_W,n_C) = result.shape\n",
        "\n",
        "# Un-Rolling the 4D image to 3D image\n",
        "reshaped_result = tf.reshape(result, shape=(m,n_H*n_W,n_C))\n",
        "\n",
        "print(reshaped_result.shape)\n",
        "os.chdir('/content/IIIT5K')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBemZvUfOsKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/IIIT5K/train')\n",
        "\n",
        "print(len(os.listdir(os.getcwd())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-Fhhav_Hikj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Need to check this fucntion. May not be needed\n",
        "'''\n",
        "\n",
        "def load_and_process_dataset():\n",
        "  '''\n",
        "    Loads and processes the images in the dataset and passes them through the\n",
        "    feature_extraction_model to get the features of each image and stores them \n",
        "    in fefatures folder. \n",
        "  '''\n",
        "  layer_name = 'mixed_7a'\n",
        "  layer_output = pre_trained_model.get_layer(layer_name).output\n",
        "  feature_extraction_model = tf.keras.Model(inputs=pre_trained_model.input, outputs=layer_output)\n",
        "  i=1\n",
        "  start = 0\n",
        "  end = 8000\n",
        "  with tqdm(total=100) as pbar:\n",
        "    for (path_to_img,label) in dataset[start:end]:\n",
        "      img = image.load_img(path_to_img, target_size=(299,299, 3))\n",
        "      img = image.img_to_array(img)\n",
        "      img = np.expand_dims(img, axis=0)\n",
        "      result = feature_extraction_model.predict(input_data)\n",
        "      (m,n_H,n_W,n_C) = result.shape\n",
        "      reshaped_result = tf.reshape(result, shape=(m,n_H*n_W,n_C))\n",
        "      t2n = tf.make_tensor_proto(reshaped_result)\n",
        "      with open(r'features_dataset', 'a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(tf.make_ndarray(t2n))\n",
        "      pbar.update((i/8000)*100)\n",
        "      #result.save(\"./features/img_\"+str(i)+\"_feature\")\n",
        "  pbar.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7psx5AYEHSAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "May not be needded\n",
        "'''\n",
        "#os.chdir('train')\n",
        "load_and_process_dataset()\n",
        "os.chdir('/content/IIIT5K')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW_Xq7_km8Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "May not be needded\n",
        "'''\n",
        "os.chdir('train')\n",
        "print(\"features_dataset\" in os.listdir(os.getcwd()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6c24eQOo_u0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "May not be needded\n",
        "'''\n",
        "!zip -r /content/features_dataset.zip features_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oUV0roJbm85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "'''\tPlotting Various Features obtained from feature_extraction_model. '''\n",
        "\n",
        "plot_limit = 8\n",
        "index = 1\n",
        "i=1500\n",
        "for _ in range(plot_limit):\n",
        "\tfor _ in range(plot_limit):\n",
        "\t\t# specify subplot and turn of axis\n",
        "\t\tax = plt.subplot(plot_limit, plot_limit, index)\n",
        "\t\tax.set_xticks([])\n",
        "\t\tax.set_yticks([])\n",
        "\t\t# plot filter channel in grayscale\n",
        "\t\tplt.imshow(result[0, :, :, i-1], cmap='gray')\n",
        "\t\tindex += 1;i-=1\n",
        "# show the figure\n",
        "plt.show()\n",
        "# Saving the Plot for future reference.\n",
        "plt.savefig('Activations.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX2VMT1_NPke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PLoting various features from the feature_extraction_model\n",
        "plot_limit = 8\n",
        "index = 1\n",
        "layer_no = 1087\n",
        "for _ in range(plot_limit):\n",
        "\tfor _ in range(plot_limit):\n",
        "\t\t# specify subplot and turn of axis\n",
        "\t\tax = plt.subplot(plot_limit, plot_limit, index)\n",
        "\t\tax.set_xticks([])\n",
        "\t\tax.set_yticks([])\n",
        "\t\t# plot filter channel in grayscale\n",
        "\t\tplt.imshow(result[0, :, :, layer_no], cmap='gray')\n",
        "\t\tindex += 1;layer_no -= 1;\n",
        "# show the figure\n",
        "plt.show()\n",
        "plt.savefig('Activations.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLyML8InXuEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def string_to_int(string, length, vocab):\n",
        "  '''\n",
        "    Converts words to list of numbers\n",
        "\n",
        "    Args : \n",
        "    string : str. The word which is to be converted to list of numbers.\n",
        "    length : int. Max length limit of the list. strings over length are removed.\n",
        "    vocab : dict. Dictonary which contains letter to number encoding.\n",
        "\n",
        "    Returns : \n",
        "    rep : list. a list of numbers representing the word\n",
        "  '''\n",
        "  \n",
        "  # converting the word to lowercase\n",
        "  string = string.lower()\n",
        "\n",
        "  # neglect the letters of the word, if the length of the word is\n",
        "  # greater than the threshold(length)\n",
        "  if len(string) > length:\n",
        "      string = string[:length]\n",
        "  rep = list(map(lambda x: vocab.get(x, '<unk>'), string))\n",
        "\n",
        "  # Add padding for the letters of the word if the length of the word is\n",
        "  # less than the threshold(length)\n",
        "  if len(string) < length:\n",
        "      rep += [vocab['<pad>']] * (length - len(string))\n",
        "\n",
        "  return rep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYG1-AA7cx5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vocabulary has been taken from internet \n",
        "vocab = {\n",
        "          ' ': 0, '.': 1, '/': 2, '0': 3, '1': 4, '2': 5, '3': 6, '4': 7, '5': 8,\n",
        "         '6': 9, '7': 10, '8': 11, '9': 12, 'a': 13, 'b': 14, 'c': 15, 'd': 16, \n",
        "         'e': 17, 'f': 18, 'g': 19, 'h': 20, 'i': 21, 'j': 22, 'l': 23, 'm': 24,\n",
        "         'n': 25, 'o': 26, 'p': 27, 'r': 28, 's': 29, 't': 30, 'u': 31, 'v': 32,\n",
        "         'w': 33, 'y': 34, '<unk>': 35, '<pad>': 36\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXnWuYzaX_cR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_output(filename,T_Y,vocab):\n",
        "\n",
        "  os.chdir('/content/IIIT5K')\n",
        "  text_file = open(filename, \"r\")\n",
        "  text = text_file.readlines()\n",
        "  text_list = [ word[0:len(word)-1] for word in text]\n",
        "\n",
        "  Y = np.array([string_to_int(word,T_Y,vocab) for word in text_list])\n",
        "\n",
        "  return Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_X_loTWBaPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8pQQ6aeBbA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ARVOAgBBa-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FONQHMu5Ba6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHIW6dBVBa46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyTOrPVJBaNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqPOyaJQBaLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p6RfwLHX_ib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_array = load_output(\"Train_labels.txt\",20,vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie5KpN5rX_mA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_a = 64 # number of units for the pre-attention, bi-directional LSTM's hidden state 'a'\n",
        "n_s = 120 # number of units for the post-attention, bi-directionsl LSTM's hidden state \"s\"\n",
        "T_X = list(reshaped_result.shape)[1]\n",
        "feature_length = list(reshaped_result.shape)[2] \n",
        "T_Y = 20\n",
        "print(T_X,feature_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlwEMh94X_hT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defined shared layers as global variables\n",
        "repeat = RepeatVector(T_X)\n",
        "concat = Concatenate(axis=-1)\n",
        "dense1 = Dense(510, activation = \"tanh\")\n",
        "dense2 = Dense(1, activation = \"relu\")\n",
        "activation = Activation(activation=\"softmax\", name='attention_weights')\n",
        "dot = Dot(axes = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRx3abM3X_Xf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attention(a, s_prev):\n",
        "  s_prev = repeat(s_prev)\n",
        "  concat_value = concat([a,s_prev])\n",
        "  e = dense1(concat_value)\n",
        "  energies = dense2(e)\n",
        "  alphas = activation(energies)\n",
        "  context = dot([alphas,a])\n",
        "  return context"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfyWA2PKYTmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "post_activation_LSTM_cell = tf.keras.layers.GRU(512\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "output_layer = Dense(20, activation=\"softmax\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reJyWEJkYTqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2seq_model(T_X, T_Y, n_a, n_s,feature_length):\n",
        "\n",
        "  X = Input(shape=(T_X, feature_length))\n",
        "  s0 = Input(shape=(n_s,), name='s0')\n",
        "  c0 = Input(shape=(n_s,), name='c0')\n",
        "  s = s0\n",
        "  c = c0\n",
        "  outputs = []\n",
        "  tf.expand_dims(s, axis = 1).shape.as_list()\n",
        "  print(s,c)\n",
        "\n",
        "  a = tf.keras.layers.GRU(512,\n",
        "                          return_sequences=True,\n",
        "                          return_state=True,\n",
        "                          recurrent_initializer='glorot_uniform')\n",
        "  for t in range(T_Y):\n",
        "        context = attention(a,s)\n",
        "        print(context)\n",
        "        s, _, c = post_activation_LSTM_cell(context)\n",
        "        out = output_layer(s)\n",
        "        outputs.append(out)\n",
        "\n",
        "  model = Model(inputs = [X,s0,c0], outputs = outputs)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRgg9WwmYTkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = seq2seq_model(T_X, T_Y, n_a, n_s, feature_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCH181-2Bcs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtqW-2RwBcpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VHSLHg1Bcnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM_yo26T5uyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JY9xoLP_6Oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hV2sDYW_6R6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(tf.keras.Model):\n",
        "  def __init__(self,units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.fc1 = tf.keras.layers.Dense(units)\n",
        "    self.fc2 = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call():\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5St37El_6Vw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVXl2p6nBeKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTsoVoHPBePZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzGmtNzXBezy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjZ1d8N1Bew6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG4RdumZ_6MK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_name_vector = []\n",
        "img_label_name = []\n",
        "\n",
        "for (image_name,label) in dataset:\n",
        "  img_name_vector.append(image_name)\n",
        "  img_label_name.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77XHInRiXt6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encode_train = sorted(set(img_name_vector))\n",
        "image_dataset = tf.data.Dataset.from_tensor_slices(encode_train)\n",
        "image_dataset = image_dataset.map(\n",
        "  load_and_process_img, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(16)\n",
        "\n",
        "for img, path in image_dataset:\n",
        "  batch_features = image_features_extract_model(img)\n",
        "  batch_features = tf.reshape(batch_features,\n",
        "                              (batch_features.shape[0], -1, batch_features.shape[3]))\n",
        "\n",
        "  for bf, p in zip(batch_features, path):\n",
        "    path_of_feature = p.numpy().decode(\"utf-8\")\n",
        "    np.save(path_of_feature, bf.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFxrQJzBCx8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_name_train, img_name_val, output_label_train, output_label_val = train_test_split(\n",
        "                                                                    img_name_vector,\n",
        "                                                                    img_label_name,\n",
        "                                                                    test_size=0.2,\n",
        "                                                                    random_state=0)\n",
        "\n",
        "len(img_name_train), len(output_label_train), len(img_name_val), len(output_label_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWe5gPb5hPWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "embedding_dim = 256\n",
        "units = 512\n",
        "vocab_size = top_k + 1\n",
        "num_steps = len(img_name_train) // BATCH_SIZE\n",
        "# Shape of the vector extracted from InceptionV3 is (64, 2048)\n",
        "# These two variables represent that vector shape\n",
        "features_shape = 2048\n",
        "attention_features_shape = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYiJR4qah34B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def map_func(img_name, cap):\n",
        "  img_tensor = np.load(img_name.decode('utf-8')+'.npy')\n",
        "  return img_tensor, cap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yieFv7bmh37I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((img_name_train, cap_train))\n",
        "\n",
        "# Use map to load the numpy files in parallel\n",
        "dataset = dataset.map(lambda item1, item2: tf.numpy_function(\n",
        "          map_func, [item1, item2], [tf.float32, tf.int32]),\n",
        "          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Shuffle and batch\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig7N8EppAi8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpYrjqP5Ai6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI4iZmobhPbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN_Encoder(tf.keras.Model):\n",
        "    # Since you have already extracted the features and dumped it using pickle\n",
        "    # This encoder passes those features through a Fully connected layer\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(CNN_Encoder, self).__init__()\n",
        "        # shape after fc == (batch_size, 64, embedding_dim)\n",
        "        self.fc = tf.keras.layers.Dense(embedding_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD40XTMlXg0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, features, hidden):\n",
        "    # features(CNN_encoder output) shape == (batch_size, 64, embedding_dim)\n",
        "\n",
        "    # hidden shape == (batch_size, hidden_size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden_size)\n",
        "    hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "\n",
        "    # score shape == (batch_size, 64, hidden_size)\n",
        "    score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
        "\n",
        "    # attention_weights shape == (batch_size, 64, 1)\n",
        "    # you get 1 at the last axis because you are applying score to self.V\n",
        "    attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * features\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_7D0sBglPkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN_Decoder(tf.keras.Model):\n",
        "  def __init__(self, embedding_dim, units, vocab_size):\n",
        "    super(RNN_Decoder, self).__init__()\n",
        "    self.units = units\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc1 = tf.keras.layers.Dense(self.units)\n",
        "    self.fc2 = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    self.attention = BahdanauAttention(self.units)\n",
        "\n",
        "  def call(self, x, features, hidden):\n",
        "    # defining attention as a separate model\n",
        "    context_vector, attention_weights = self.attention(features, hidden)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # shape == (batch_size, max_length, hidden_size)\n",
        "    x = self.fc1(output)\n",
        "\n",
        "    # x shape == (batch_size * max_length, hidden_size)\n",
        "    x = tf.reshape(x, (-1, x.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size * max_length, vocab)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x, state, attention_weights\n",
        "\n",
        "  def reset_state(self, batch_size):\n",
        "    return tf.zeros((batch_size, self.units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSS7nhA5XYx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 256\n",
        "units = 512\n",
        "vocab_size = len(list(vocab.keys()))\n",
        "encoder = CNN_Encoder(embedding_dim)\n",
        "decoder = RNN_Decoder(embedding_dim, units, vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJsuxbGiYbWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnIaaLaMYbar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "ckpt = tf.train.Checkpoint(encoder=encoder,\n",
        "                           decoder=decoder,\n",
        "                           optimizer = optimizer)\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYHJDm1nzaFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_epoch = 0\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n",
        "  # restoring the latest checkpoint in checkpoint_path\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozIWrQN7zaD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_plot = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkcy_l5Azkmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(img_tensor, target):\n",
        "  loss = 0\n",
        "\n",
        "  # initializing the hidden state for each batch\n",
        "  # because the captions are not related from image to image\n",
        "  hidden = decoder.reset_state(batch_size=target.shape[0])\n",
        "\n",
        "  dec_input = tf.expand_dims([1] * target.shape[0], 1)\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "      features = encoder(img_tensor)\n",
        "\n",
        "      for i in range(1, target.shape[1]):\n",
        "          # passing the features through the decoder\n",
        "          predictions, hidden, _ = decoder(dec_input, features, hidden)\n",
        "\n",
        "          loss += loss_function(target[:, i], predictions)\n",
        "\n",
        "          # using teacher forcing\n",
        "          dec_input = tf.expand_dims(target[:, i], 1)\n",
        "\n",
        "  total_loss = (loss / int(target.shape[1]))\n",
        "\n",
        "  trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, trainable_variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "\n",
        "  return loss, total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV0SDX1V1Qe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjyTpMuczkqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "    start = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (img_tensor, target)) in enumerate(dataset):\n",
        "        batch_loss, t_loss = train_step(img_tensor, target)\n",
        "        total_loss += t_loss\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print ('Epoch {} Batch {} Loss {:.4f}'.format(\n",
        "              epoch + 1, batch, batch_loss.numpy() / int(target.shape[1])))\n",
        "    # storing the epoch end loss value to plot later\n",
        "    loss_plot.append(total_loss / num_steps)\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "      ckpt_manager.save()\n",
        "\n",
        "    print ('Epoch {} Loss {:.6f}'.format(epoch + 1,\n",
        "                                         total_loss/num_steps))\n",
        "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQAWYyIozklb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-iPp1FzzZ_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLX3uDRBYbVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZZqcd83xDwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone \"https://github.com/oh-my-ocr/text_renderer\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwG9V8_txGlq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"text_renderer\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvao_NM9KRh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(r'name', 'a') as f:\n",
        "  for i in range(12):\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnCRDyDOJ6Tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 setup.py develop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNqkYOT1xLwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install -r docker/requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArT6fN_NxN5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 main.py \\\n",
        "    --config example_data/example.py \\\n",
        "    --dataset img \\\n",
        "    --num_processes 2 \\\n",
        "    --log_period 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPU3geHixPtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r Dataset.zip /content/output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7IZvT33xRa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('Dataset.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGoMODP-jcIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone --single-branch --branch python3 \"https://github.com/ankush-me/SynthText.git\" "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}